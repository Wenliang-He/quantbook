<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Quantitative Research Methods for Education</title>
  <meta name="description" content="This is the first trial version!">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Quantitative Research Methods for Education" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the first trial version!" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Quantitative Research Methods for Education" />
  
  <meta name="twitter:description" content="This is the first trial version!" />
  

<meta name="author" content="Wenliang He">


<meta name="date" content="2018-08-12">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="the-fundamentals-of-statistics.html">
<link rel="next" href="statistical-inference-2.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<script src="libs/d3-3.3.8/d3.min.js"></script>
<script src="libs/dagre-0.4.0/dagre-d3.min.js"></script>
<link href="libs/mermaid-0.3.0/dist/mermaid.css" rel="stylesheet" />
<script src="libs/mermaid-0.3.0/dist/mermaid.slim.min.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/chromatography-0.1/chromatography.js"></script>
<script src="libs/DiagrammeR-binding-1.0.0/DiagrammeR.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#intro-to-rmarkdown"><i class="fa fa-check"></i><b>1.1</b> Intro to Rmarkdown</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#intro-to-bookdown"><i class="fa fa-check"></i><b>1.2</b> Intro to Bookdown</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#resources-to-rmarkdown"><i class="fa fa-check"></i><b>1.3</b> Resources to Rmarkdown</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#resources-to-bookdown"><i class="fa fa-check"></i><b>1.4</b> Resources to Bookdown</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="a-brief-r-tutorial.html"><a href="a-brief-r-tutorial.html"><i class="fa fa-check"></i><b>2</b> A Brief R Tutorial</a><ul>
<li class="chapter" data-level="2.1" data-path="a-brief-r-tutorial.html"><a href="a-brief-r-tutorial.html#essential-basics---intro"><i class="fa fa-check"></i><b>2.1</b> Essential Basics - intro</a></li>
<li class="chapter" data-level="2.2" data-path="a-brief-r-tutorial.html"><a href="a-brief-r-tutorial.html#atomic-data-types---atomic-dtype"><i class="fa fa-check"></i><b>2.2</b> Atomic Data Types - atomic-dtype</a><ul>
<li class="chapter" data-level="2.2.1" data-path="a-brief-r-tutorial.html"><a href="a-brief-r-tutorial.html#logical---logical"><i class="fa fa-check"></i><b>2.2.1</b> Logical - logical</a></li>
<li class="chapter" data-level="2.2.2" data-path="a-brief-r-tutorial.html"><a href="a-brief-r-tutorial.html#integer---integer"><i class="fa fa-check"></i><b>2.2.2</b> Integer - integer</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-fundamentals-of-statistics.html"><a href="the-fundamentals-of-statistics.html"><i class="fa fa-check"></i><b>3</b> The Fundamentals of Statistics</a><ul>
<li class="chapter" data-level="3.1" data-path="the-fundamentals-of-statistics.html"><a href="the-fundamentals-of-statistics.html#why-studying-statistics"><i class="fa fa-check"></i><b>3.1</b> Why Studying Statistics</a><ul>
<li class="chapter" data-level="3.1.1" data-path="the-fundamentals-of-statistics.html"><a href="the-fundamentals-of-statistics.html#understanding-the-world"><i class="fa fa-check"></i><b>3.1.1</b> Understanding the World</a></li>
<li class="chapter" data-level="3.1.2" data-path="the-fundamentals-of-statistics.html"><a href="the-fundamentals-of-statistics.html#science-vs.philosophy"><i class="fa fa-check"></i><b>3.1.2</b> Science vs. Philosophy</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="the-fundamentals-of-statistics.html"><a href="the-fundamentals-of-statistics.html#the-big-picture"><i class="fa fa-check"></i><b>3.2</b> The Big Picture</a><ul>
<li class="chapter" data-level="3.2.1" data-path="the-fundamentals-of-statistics.html"><a href="the-fundamentals-of-statistics.html#central-themes-in-statistics"><i class="fa fa-check"></i><b>3.2.1</b> Central Themes in Statistics</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="the-fundamentals-of-statistics.html"><a href="the-fundamentals-of-statistics.html#the-fundamentals-of-statistics-1"><i class="fa fa-check"></i><b>3.3</b> The Fundamentals of Statistics</a><ul>
<li class="chapter" data-level="3.3.1" data-path="the-fundamentals-of-statistics.html"><a href="the-fundamentals-of-statistics.html#storing-data-in-tables"><i class="fa fa-check"></i><b>3.3.1</b> Storing Data in Tables</a></li>
<li class="chapter" data-level="3.3.2" data-path="the-fundamentals-of-statistics.html"><a href="the-fundamentals-of-statistics.html#variable-types"><i class="fa fa-check"></i><b>3.3.2</b> Variable Types</a></li>
<li class="chapter" data-level="3.3.3" data-path="the-fundamentals-of-statistics.html"><a href="the-fundamentals-of-statistics.html#exploratory-data-analysis-checking-distributions"><i class="fa fa-check"></i><b>3.3.3</b> Exploratory Data Analysis: Checking Distributions</a></li>
<li class="chapter" data-level="3.3.4" data-path="the-fundamentals-of-statistics.html"><a href="the-fundamentals-of-statistics.html#normal-distributions"><i class="fa fa-check"></i><b>3.3.4</b> Normal Distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>4</b> Statistical Inference</a><ul>
<li class="chapter" data-level="4.1" data-path="statistical-inference.html"><a href="statistical-inference.html#random-variable"><i class="fa fa-check"></i><b>4.1</b> Random Variable</a><ul>
<li class="chapter" data-level="4.1.1" data-path="statistical-inference.html"><a href="statistical-inference.html#iid---independently-and-identically-distributed"><i class="fa fa-check"></i><b>4.1.1</b> IID - Independently and Identically Distributed</a></li>
<li class="chapter" data-level="4.1.2" data-path="statistical-inference.html"><a href="statistical-inference.html#random-variable-vs.case"><i class="fa fa-check"></i><b>4.1.2</b> Random Variable vs. Case</a></li>
<li class="chapter" data-level="4.1.3" data-path="statistical-inference.html"><a href="statistical-inference.html#properties-of-a-random-variable"><i class="fa fa-check"></i><b>4.1.3</b> Properties of a Random Variable</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="statistical-inference.html"><a href="statistical-inference.html#central-limit-theorem"><i class="fa fa-check"></i><b>4.2</b> Central Limit Theorem</a><ul>
<li class="chapter" data-level="4.2.1" data-path="statistical-inference.html"><a href="statistical-inference.html#presenting-central-limit-theorem"><i class="fa fa-check"></i><b>4.2.1</b> Presenting Central Limit Theorem</a></li>
<li class="chapter" data-level="4.2.2" data-path="statistical-inference.html"><a href="statistical-inference.html#understanding-central-limit-theorem"><i class="fa fa-check"></i><b>4.2.2</b> Understanding Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="statistical-inference.html"><a href="statistical-inference.html#statistical-inference-1"><i class="fa fa-check"></i><b>4.3</b> Statistical Inference</a><ul>
<li class="chapter" data-level="4.3.1" data-path="statistical-inference.html"><a href="statistical-inference.html#the-diamond-expert"><i class="fa fa-check"></i><b>4.3.1</b> The Diamond Expert</a></li>
<li class="chapter" data-level="4.3.2" data-path="statistical-inference.html"><a href="statistical-inference.html#hypothesis-testing"><i class="fa fa-check"></i><b>4.3.2</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="4.3.3" data-path="statistical-inference.html"><a href="statistical-inference.html#hypothesis-testing-with-unknown-variance"><i class="fa fa-check"></i><b>4.3.3</b> Hypothesis Testing with Unknown Variance</a></li>
<li class="chapter" data-level="4.3.4" data-path="statistical-inference.html"><a href="statistical-inference.html#examples-of-hypothesis-testing"><i class="fa fa-check"></i><b>4.3.4</b> Examples of Hypothesis Testing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="statistical-inference-2.html"><a href="statistical-inference-2.html"><i class="fa fa-check"></i><b>5</b> Statistical Inference</a><ul>
<li class="chapter" data-level="5.1" data-path="statistical-inference-2.html"><a href="statistical-inference-2.html#random-variable-1"><i class="fa fa-check"></i><b>5.1</b> Random Variable</a><ul>
<li class="chapter" data-level="5.1.1" data-path="statistical-inference-2.html"><a href="statistical-inference-2.html#get-a-sample-of-data"><i class="fa fa-check"></i><b>5.1.1</b> Get a Sample of Data</a></li>
<li class="chapter" data-level="5.1.2" data-path="statistical-inference-2.html"><a href="statistical-inference-2.html#iid---independently-and-identically-distributed-1"><i class="fa fa-check"></i><b>5.1.2</b> IID - Independently and Identically Distributed</a></li>
<li class="chapter" data-level="5.1.3" data-path="statistical-inference-2.html"><a href="statistical-inference-2.html#random-variables-vs.cases"><i class="fa fa-check"></i><b>5.1.3</b> Random Variables vs. Cases</a></li>
<li class="chapter" data-level="5.1.4" data-path="statistical-inference-2.html"><a href="statistical-inference-2.html#properties-of-a-random-variable-1"><i class="fa fa-check"></i><b>5.1.4</b> Properties of a Random Variable</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="statistical-inference-2.html"><a href="statistical-inference-2.html#central-limit-theorem-1"><i class="fa fa-check"></i><b>5.2</b> Central Limit Theorem</a><ul>
<li class="chapter" data-level="5.2.1" data-path="statistical-inference-2.html"><a href="statistical-inference-2.html#intro-to-central-limit-theorem"><i class="fa fa-check"></i><b>5.2.1</b> Intro to Central Limit Theorem</a></li>
<li class="chapter" data-level="5.2.2" data-path="statistical-inference-2.html"><a href="statistical-inference-2.html#more-on-central-limit-theorem"><i class="fa fa-check"></i><b>5.2.2</b> More on Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="statistical-inference-2.html"><a href="statistical-inference-2.html#intro-to-statistical-inference"><i class="fa fa-check"></i><b>5.3</b> Intro to Statistical Inference</a><ul>
<li class="chapter" data-level="5.3.1" data-path="statistical-inference-2.html"><a href="statistical-inference-2.html#the-diamond-expert-1"><i class="fa fa-check"></i><b>5.3.1</b> The Diamond Expert</a></li>
<li class="chapter" data-level="5.3.2" data-path="statistical-inference-2.html"><a href="statistical-inference-2.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>5.3.2</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="5.3.3" data-path="statistical-inference-2.html"><a href="statistical-inference-2.html#hypothesis-testing-with-unknown-variance-1"><i class="fa fa-check"></i><b>5.3.3</b> Hypothesis Testing with Unknown Variance</a></li>
<li class="chapter" data-level="5.3.4" data-path="statistical-inference-2.html"><a href="statistical-inference-2.html#examples-of-hypothesis-testing-1"><i class="fa fa-check"></i><b>5.3.4</b> Examples of Hypothesis Testing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html"><i class="fa fa-check"></i><b>6</b> Common Statistical Tests</a><ul>
<li class="chapter" data-level="6.1" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html#dummy-x---continuous-y"><i class="fa fa-check"></i><b>6.1</b> Dummy (X) - Continuous (Y)</a><ul>
<li class="chapter" data-level="6.1.1" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html#two-sample-t-test"><i class="fa fa-check"></i><b>6.1.1</b> Two-sample T-Test</a></li>
<li class="chapter" data-level="6.1.2" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html#statistical-power"><i class="fa fa-check"></i><b>6.1.2</b> Statistical Power</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html#dummy-x---dummy-y"><i class="fa fa-check"></i><b>6.2</b> Dummy (X) - Dummy (Y)</a><ul>
<li class="chapter" data-level="6.2.1" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html#basics"><i class="fa fa-check"></i><b>6.2.1</b> Basics</a></li>
<li class="chapter" data-level="6.2.2" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html#difference-in-proportions"><i class="fa fa-check"></i><b>6.2.2</b> Difference in Proportions</a></li>
<li class="chapter" data-level="6.2.3" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html#relative-risks"><i class="fa fa-check"></i><b>6.2.3</b> Relative Risks</a></li>
<li class="chapter" data-level="6.2.4" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html#odds-ratio"><i class="fa fa-check"></i><b>6.2.4</b> Odds Ratio</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html#categorical-x---dummy-y"><i class="fa fa-check"></i><b>6.3</b> Categorical (X) - Dummy (Y)</a><ul>
<li class="chapter" data-level="6.3.1" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html#basics-1"><i class="fa fa-check"></i><b>6.3.1</b> Basics</a></li>
<li class="chapter" data-level="6.3.2" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html#chi-squared-test"><i class="fa fa-check"></i><b>6.3.2</b> Chi-squared Test</a></li>
<li class="chapter" data-level="6.3.3" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html#g-square-test"><i class="fa fa-check"></i><b>6.3.3</b> G-square Test</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html#categorical-x---continuous-y"><i class="fa fa-check"></i><b>6.4</b> Categorical (X) - Continuous (Y)</a><ul>
<li class="chapter" data-level="6.4.1" data-path="common-statistical-tests.html"><a href="common-statistical-tests.html#anova"><i class="fa fa-check"></i><b>6.4.1</b> ANOVA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>7</b> Linear Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="linear-regression.html"><a href="linear-regression.html#table-of-contents"><i class="fa fa-check"></i><b>7.1</b> Table of Contents</a></li>
<li class="chapter" data-level="7.2" data-path="linear-regression.html"><a href="linear-regression.html#pearson-product-moment-correlation-coefficient"><i class="fa fa-check"></i><b>7.2</b> Pearson Product-Moment Correlation Coefficient</a><ul>
<li class="chapter" data-level="7.2.1" data-path="linear-regression.html"><a href="linear-regression.html#definition"><i class="fa fa-check"></i><b>7.2.1</b> Definition</a></li>
<li class="chapter" data-level="7.2.2" data-path="linear-regression.html"><a href="linear-regression.html#properties-of-pearson-correlation"><i class="fa fa-check"></i><b>7.2.2</b> Properties of Pearson Correlation</a></li>
<li class="chapter" data-level="7.2.3" data-path="linear-regression.html"><a href="linear-regression.html#limitations-of-pearson-correlation"><i class="fa fa-check"></i><b>7.2.3</b> Limitations of Pearson Correlation</a></li>
<li class="chapter" data-level="7.2.4" data-path="linear-regression.html"><a href="linear-regression.html#other-issues-on-the-usage-of-pearson-correlation"><i class="fa fa-check"></i><b>7.2.4</b> Other Issues on the Usage of Pearson Correlation</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="linear-regression.html"><a href="linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>7.3</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="7.3.1" data-path="linear-regression.html"><a href="linear-regression.html#independent-variable-from-categorical-to-continuous"><i class="fa fa-check"></i><b>7.3.1</b> Independent Variable: From Categorical to Continuous</a></li>
<li class="chapter" data-level="7.3.2" data-path="linear-regression.html"><a href="linear-regression.html#fitting-a-straight-line-to-data"><i class="fa fa-check"></i><b>7.3.2</b> Fitting a Straight Line to Data</a></li>
<li class="chapter" data-level="7.3.3" data-path="linear-regression.html"><a href="linear-regression.html#the-least-squares-method"><i class="fa fa-check"></i><b>7.3.3</b> The Least-Squares Method</a></li>
<li class="chapter" data-level="7.3.4" data-path="linear-regression.html"><a href="linear-regression.html#interpretations-of-regression-coefficients"><i class="fa fa-check"></i><b>7.3.4</b> Interpretations of Regression Coefficients</a></li>
<li class="chapter" data-level="7.3.5" data-path="linear-regression.html"><a href="linear-regression.html#understanding-the-estimators"><i class="fa fa-check"></i><b>7.3.5</b> Understanding the Estimators</a></li>
<li class="chapter" data-level="7.3.6" data-path="linear-regression.html"><a href="linear-regression.html#residual-variance"><i class="fa fa-check"></i><b>7.3.6</b> Residual Variance</a></li>
<li class="chapter" data-level="7.3.7" data-path="linear-regression.html"><a href="linear-regression.html#standard-error-of-the-slope"><i class="fa fa-check"></i><b>7.3.7</b> Standard Error of the Slope</a></li>
<li class="chapter" data-level="7.3.8" data-path="linear-regression.html"><a href="linear-regression.html#effect-size-and-standardized-coefficients"><i class="fa fa-check"></i><b>7.3.8</b> Effect Size and Standardized Coefficients</a></li>
<li class="chapter" data-level="7.3.9" data-path="linear-regression.html"><a href="linear-regression.html#anova-for-regression"><i class="fa fa-check"></i><b>7.3.9</b> ANOVA for Regression</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="linear-regression.html"><a href="linear-regression.html#non-linear-relations"><i class="fa fa-check"></i><b>7.4</b> Non-linear Relations</a><ul>
<li class="chapter" data-level="7.4.1" data-path="linear-regression.html"><a href="linear-regression.html#log-transformations"><i class="fa fa-check"></i><b>7.4.1</b> Log-transformations</a></li>
<li class="chapter" data-level="7.4.2" data-path="linear-regression.html"><a href="linear-regression.html#quadratic-relations"><i class="fa fa-check"></i><b>7.4.2</b> Quadratic Relations</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="linear-regression.html"><a href="linear-regression.html#the-assumptions-of-simple-linear-regression"><i class="fa fa-check"></i><b>7.5</b> The Assumptions of Simple Linear Regression</a></li>
<li class="chapter" data-level="7.6" data-path="linear-regression.html"><a href="linear-regression.html#assumption-diagnostics"><i class="fa fa-check"></i><b>7.6</b> Assumption Diagnostics</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>8</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="8.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#regression-models---the-base-form"><i class="fa fa-check"></i><b>8.1</b> Regression Models - The Base Form</a><ul>
<li class="chapter" data-level="8.1.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#model-specification-with-population-parameters"><i class="fa fa-check"></i><b>8.1.1</b> Model Specification with Population Parameters</a></li>
<li class="chapter" data-level="8.1.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#model-specification-with-sample-parameters"><i class="fa fa-check"></i><b>8.1.2</b> Model Specification with Sample Parameters</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#the-ordinary-least-squres-method"><i class="fa fa-check"></i><b>8.2</b> The Ordinary Least-Squres Method</a><ul>
<li class="chapter" data-level="8.2.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#interpretations-of-regression-coefficients-1"><i class="fa fa-check"></i><b>8.2.1</b> Interpretations of Regression Coefficients</a></li>
<li class="chapter" data-level="8.2.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#residual-variance-1"><i class="fa fa-check"></i><b>8.2.2</b> Residual Variance</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#standard-errors-of-regression-coefficients"><i class="fa fa-check"></i><b>8.3</b> Standard Errors of Regression Coefficients</a><ul>
<li class="chapter" data-level="8.3.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#variance-inflation-factor"><i class="fa fa-check"></i><b>8.3.1</b> Variance Inflation Factor</a></li>
<li class="chapter" data-level="8.3.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#significance-of-vif"><i class="fa fa-check"></i><b>8.3.2</b> Significance of VIF</a></li>
<li class="chapter" data-level="8.3.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#multicollinearity"><i class="fa fa-check"></i><b>8.3.3</b> Multicollinearity</a></li>
<li class="chapter" data-level="8.3.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#influencing-factors-on-standard-errors"><i class="fa fa-check"></i><b>8.3.4</b> Influencing Factors on Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#r2-and-anova-for-multiple-regression"><i class="fa fa-check"></i><b>8.4</b> <span class="math inline">\(R^2\)</span> and ANOVA for Multiple Regression</a></li>
<li class="chapter" data-level="8.5" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#regression-models-extended---categorical-features"><i class="fa fa-check"></i><b>8.5</b> Regression Models Extended - Categorical Features</a><ul>
<li class="chapter" data-level="8.5.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#dummy-variables"><i class="fa fa-check"></i><b>8.5.1</b> Dummy Variables</a></li>
<li class="chapter" data-level="8.5.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#nominal-variables"><i class="fa fa-check"></i><b>8.5.2</b> Nominal Variables</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#regression-models-extended---interaction-effects"><i class="fa fa-check"></i><b>8.6</b> Regression Models Extended - Interaction Effects</a><ul>
<li class="chapter" data-level="8.6.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#dummy-dummy-interactions"><i class="fa fa-check"></i><b>8.6.1</b> Dummy-Dummy Interactions</a></li>
<li class="chapter" data-level="8.6.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#dummy-continuous-interactions"><i class="fa fa-check"></i><b>8.6.2</b> Dummy-Continuous Interactions</a></li>
<li class="chapter" data-level="8.6.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#continuous-continuous-interactions"><i class="fa fa-check"></i><b>8.6.3</b> Continuous-Continuous Interactions</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#regression-models-extended---nonlinear-relations"><i class="fa fa-check"></i><b>8.7</b> Regression Models Extended - Nonlinear Relations</a></li>
<li class="chapter" data-level="8.8" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#model-comparision-evaluation"><i class="fa fa-check"></i><b>8.8</b> Model Comparision &amp; Evaluation</a><ul>
<li class="chapter" data-level="8.8.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#f-test-for-nested-models"><i class="fa fa-check"></i><b>8.8.1</b> F-test for Nested Models</a></li>
<li class="chapter" data-level="8.8.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#adjusted-r-squared"><i class="fa fa-check"></i><b>8.8.2</b> Adjusted R-Squared</a></li>
<li class="chapter" data-level="8.8.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#information-criteria"><i class="fa fa-check"></i><b>8.8.3</b> Information Criteria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html"><i class="fa fa-check"></i><b>9</b> Key Formatting Constructs</a><ul>
<li class="chapter" data-level="9.1" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#emphasis"><i class="fa fa-check"></i><b>9.1</b> Emphasis</a></li>
<li class="chapter" data-level="9.2" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#superscripts"><i class="fa fa-check"></i><b>9.2</b> Superscripts</a></li>
<li class="chapter" data-level="9.3" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#lists"><i class="fa fa-check"></i><b>9.3</b> Lists</a><ul>
<li class="chapter" data-level="9.3.1" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#unordered"><i class="fa fa-check"></i><b>9.3.1</b> Unordered</a></li>
<li class="chapter" data-level="9.3.2" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#ordered"><i class="fa fa-check"></i><b>9.3.2</b> Ordered</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#block-quotes"><i class="fa fa-check"></i><b>9.4</b> Block Quotes</a></li>
<li class="chapter" data-level="9.5" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#displaying-blocks-of-code-without-evaluating"><i class="fa fa-check"></i><b>9.5</b> Displaying Blocks of Code Without Evaluating</a></li>
<li class="chapter" data-level="9.6" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#displaying-r-code-inline-in-a-sentence"><i class="fa fa-check"></i><b>9.6</b> Displaying R Code Inline in a Sentence</a></li>
<li class="chapter" data-level="9.7" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#evaluating-and-inserting-r-code-in-a-sentence"><i class="fa fa-check"></i><b>9.7</b> Evaluating and Inserting R Code in a Sentence</a></li>
<li class="chapter" data-level="9.8" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#typesetting-equations"><i class="fa fa-check"></i><b>9.8</b> Typesetting Equations</a></li>
<li class="chapter" data-level="9.9" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#inline-vs.display-material"><i class="fa fa-check"></i><b>9.9</b> Inline vs. Display Material</a></li>
<li class="chapter" data-level="9.10" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#some-latex-basics"><i class="fa fa-check"></i><b>9.10</b> Some LaTeX Basics</a><ul>
<li class="chapter" data-level="9.10.1" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#self-sizing-parentheses"><i class="fa fa-check"></i><b>9.10.1</b> Self-Sizing Parentheses</a></li>
<li class="chapter" data-level="9.10.2" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#special-functions"><i class="fa fa-check"></i><b>9.10.2</b> Special Functions</a></li>
<li class="chapter" data-level="9.10.3" data-path="key-formatting-constructs.html"><a href="key-formatting-constructs.html#matrices"><i class="fa fa-check"></i><b>9.10.3</b> Matrices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="cheatsheet.html"><a href="cheatsheet.html"><i class="fa fa-check"></i><b>10</b> Cheatsheet</a><ul>
<li class="chapter" data-level="10.1" data-path="cheatsheet.html"><a href="cheatsheet.html#dictionary-of-symbols"><i class="fa fa-check"></i><b>10.1</b> Dictionary of Symbols</a></li>
<li class="chapter" data-level="10.2" data-path="cheatsheet.html"><a href="cheatsheet.html#including-plots"><i class="fa fa-check"></i><b>10.2</b> Including Plots</a><ul>
<li class="chapter" data-level="10.2.1" data-path="cheatsheet.html"><a href="cheatsheet.html#subscripts-and-superscripts"><i class="fa fa-check"></i><b>10.2.1</b> Subscripts and Superscripts</a></li>
<li class="chapter" data-level="10.2.2" data-path="cheatsheet.html"><a href="cheatsheet.html#operators-1"><i class="fa fa-check"></i><b>10.2.2</b> Operators 1</a></li>
<li class="chapter" data-level="10.2.3" data-path="cheatsheet.html"><a href="cheatsheet.html#operators-2"><i class="fa fa-check"></i><b>10.2.3</b> Operators 2</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Quantitative Research Methods for Education</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="statistical-inference" class="section level1">
<h1><span class="header-section-number">4</span> Statistical Inference</h1>
<div id="random-variable" class="section level2">
<h2><span class="header-section-number">4.1</span> Random Variable</h2>
<table>
<thead>
<tr class="header">
<th></th>
<th>Var1</th>
<th align="center">Var2</th>
<th>Var3</th>
<th>Var4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td></td>
<td align="center"><span class="math inline">\(y_1\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>2</td>
<td></td>
<td align="center"><span class="math inline">\(y_2\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>3</td>
<td></td>
<td align="center"><span class="math inline">\(y_3\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>4</td>
<td></td>
<td align="center"><span class="math inline">\(...\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>5</td>
<td></td>
<td align="center"><span class="math inline">\(y_n\)</span></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>What is a <strong><em>random variable</em></strong> or <strong><em>RV</em></strong>? We have rows as cases and columns as variales. How is a <em>variable</em> as we know it connected with the idea of a <em>random varible</em>?</p>
<blockquote>
<p>形而上者谓之道 - 在天成象 - 象（无形之概念、蓝图、计划）</p>
</blockquote>
<blockquote>
<p>形而下者谓之器 - 在地成形 - 现象（有形之物、器、案例）</p>
</blockquote>
<div class="figure">
<img src="images/inference_RV.png" />

</div>
<p>Let’s choose <span class="math inline">\(Y_1, Y_2, Y_3, ..., Y_n\)</span> from the standard normal distribution <span class="math inline">\(N(0,1)\)</span>.</p>
<ul>
<li>before we see the value of <span class="math inline">\(Y_i\)</span>
<ul>
<li><span class="math inline">\(Y_i\)</span> is a <strong>random variable</strong>, which is practically a probability distribution</li>
<li><span class="math inline">\(Y_1, Y_2, Y_3, ..., Y_n\)</span> is a <strong>random sample</strong></li>
<li>a statistic (e.g., <span class="math inline">\(\bar{Y} = 1/n \sum Y_i\)</span>) computed from a random sample is another <em>random variable</em> called a <strong>sampling statistic</strong></li>
</ul></li>
<li>after we see the value of <span class="math inline">\(Y_i\)</span>
<ul>
<li><span class="math inline">\(y_i\)</span> is a <strong>case</strong>, which is a specific number</li>
<li><span class="math inline">\(y_1, y_2, y_3, ..., y_n\)</span> is a <strong>sample</strong></li>
<li>a statistic (e.g., <span class="math inline">\(m=1/n \sum y_i\)</span>) computed from a sample is a <em>number</em> called a <strong>sample statistic</strong></li>
</ul></li>
</ul>
<p>In this context, the word <strong>random</strong> means <strong>unsettled</strong>. The value of a <em>random</em> variable will not be <em>settled</em> unless it is actually sampled and observed, i.e., an actual data point is collected.</p>
<div id="iid---independently-and-identically-distributed" class="section level3">
<h3><span class="header-section-number">4.1.1</span> IID - Independently and Identically Distributed</h3>
<p>The phrase, let’s choose <span class="math inline">\(Y_1, Y_2, Y_3, ..., Y_n\)</span> from the standard normal distribution <span class="math inline">\(N(0,1)\)</span>, can be succinctly summarized as follows:</p>
<p><span class="math display">\[Y_1, Y_2, Y_3, ..., Y_n \overset{iid}{\sim} N(0,1) \]</span> where <strong>iid</strong> means <strong>i</strong>ndependently and <strong>i</strong>dentically <strong>d</strong>istributed.</p>
<div id="identically-distributed" class="section level4">
<h4><span class="header-section-number">4.1.1.1</span> Identically Distributed</h4>
<div id="htmlwidget-a8f04f28f989bfa3f97e" style="width:672px;height:100px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-a8f04f28f989bfa3f97e">{"x":{"diagram":"\ngraph LR\n\nA((B)) --- B((B)) \nB --- C((B)) \nC --- D((R)) \nD --- E((R))\n\nlinkStyle default stroke-width:0px\nclass A,B,C blacks\nclass D,E reds\nclassDef blacks fill:darkgray\nclassDef reds fill:red\n\n"},"evals":[],"jsHooks":[]}</script>
<p>Let’s image that we have 3 black (B) balls and 2 red (R) balls.</p>
<blockquote>
<p>If you would randomly choose a ball, what is the probability that it’s black?</p>
</blockquote>
<p><strong>Answer</strong>: <span class="math inline">\(P(B_1) = 3/5\)</span>.</p>
<blockquote>
<p>Now if we indeed pick a black ball in our first try and we decide to choose a second ball. Given that we do not put the first ball back, what is the probability that the second one is also black?</p>
</blockquote>
<p><strong>Answer</strong>: <span class="math inline">\(P(B_2) = 2/4\)</span>.</p>
<p>Hence, choosing two balls in this example violates the <strong>identically distributed</strong> assumption.</p>
<p>Two important ideas emerge in the <em>process of choosing</em> (aka <em>sampling</em>) things.</p>
<ul>
<li>In the previous sampling process, after each draw, if we do not put the balls back, this way of choosing things is called <strong><em>sampling without replacement</em></strong>.</li>
<li>In contrast, if you do put the balls back after each draw, it is called <strong><em>sampling with replacement</em></strong>.</li>
</ul>
<p>It is hence clear that the word <em>replacement</em> in this context practically means <em>putting things back</em> (or more precisely <em>finding a replacement</em> for the one that is drawn).</p>
<p>In practice, we would rarely sample with relacement. However, if the pool is large enough, we can ignore the slight change in probability after each time one case is drawn.</p>
</div>
<div id="independently-distributed" class="section level4">
<h4><span class="header-section-number">4.1.1.2</span> Independently Distributed</h4>
<p>Now let’s consider another case. Imagine that at the beginning of a semester, you as a student is trying to find a course to enroll. There are <strong>N</strong> courses in total and all courses are equally attractive (i.e., same probabiliy of being chosen by a student). You and your friend from the same dorm are discussing about the teachers and courses. Eventually, the two of you decide to enroll into the same course denoted as <strong>C</strong>.</p>
<blockquote>
<p>What are the probabilities of you and your friend enrolling into course <strong>C</strong>?</p>
</blockquote>
<p><strong>Answer</strong>: <span class="math inline">\(P(C_1) = 1/N\)</span> and <span class="math inline">\(P(C_2) = 1/N\)</span>. Since there are <strong>N</strong> courses in total and all are equally attractive, the probabilities of you and your friend enrolling into course <strong>C</strong> are the same.</p>
<blockquote>
<p>Is the probability of you enrolling into the course independent of the probability of your friend enrolling into the same course?</p>
</blockquote>
<p><strong>Answer</strong>: obviously no! Because you and your friend are not making the course enrollment decisions separately, but with much discussion going around.</p>
<p>Hence, choosing the same course in this example violates the <strong>independently distributed</strong> assumption, even though they are <em>identically distributed</em>.</p>
</div>
</div>
<div id="random-variable-vs.case" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Random Variable vs. Case</h3>
<table>
<thead>
<tr class="header">
<th></th>
<th>Random Variable(s)</th>
<th>Case(s)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>is a</td>
<td>concept</td>
<td>instance</td>
</tr>
<tr class="even">
<td>is a</td>
<td>probabiilty distribution</td>
<td>number</td>
</tr>
<tr class="odd">
<td>comprise a</td>
<td>population</td>
<td>sample</td>
</tr>
<tr class="even">
<td>with sample size</td>
<td><span class="math inline">\(n = \infty\)</span> or all data</td>
<td><span class="math inline">\(n\)</span> is finite or some data</td>
</tr>
<tr class="odd">
<td>comprise a</td>
<td>probability distribution</td>
<td>empirical spread/distribution</td>
</tr>
<tr class="even">
<td>comprise a</td>
<td>random sample</td>
<td>sample</td>
</tr>
<tr class="odd">
<td>give rise to a</td>
<td>sampling statistic</td>
<td>sample statistic</td>
</tr>
</tbody>
</table>
</div>
<div id="properties-of-a-random-variable" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Properties of a Random Variable</h3>
<p>Previously, we have <span class="math inline">\(Y_1, Y_2, Y_3, ..., Y_n \overset{iid}{\sim} N(0,1)\)</span> and <span class="math inline">\(\bar{Y} = \frac{1}{n} \sum_{i=1}^{n} Y_i\)</span>, where both <span class="math inline">\(Y_i\)</span>s and <span class="math inline">\(\bar{Y}\)</span> are random variables. In practice, we would encounter a variety of random variables. As a result, we would constantly ask the questions:</p>
<ul>
<li>What does a RV look like?</li>
<li>What is the distribution of a RV?</li>
<li>What are the properties of a RV?
<ul>
<li>center of a RV or <span class="math inline">\(E(RV)\)</span></li>
<li>spread of a RV or <span class="math inline">\(Var(RV)\)</span></li>
<li>shape of a RV or <span class="math inline">\(shape(RV)\)</span></li>
</ul></li>
</ul>
<p>The first two questions are identical. The first one is using informal language and the second using formal academic language. The two questions are reduced to the third question, which is basically asking for a quick summary of a distribution in terms of the <em>center</em>, <em>spread</em>, and <em>shape</em>.</p>
<p>The properties of a RV can be succintly summarized as</p>
<p><span class="math display">\[Y \sim \forall(\mu, \sigma^2) \]</span> where <span class="math inline">\(\forall\)</span> stands for <strong><em>any</em></strong>. Notice <span class="math inline">\(\forall\)</span> is just an inverted <strong>A</strong>.</p>
</div>
</div>
<div id="central-limit-theorem" class="section level2">
<h2><span class="header-section-number">4.2</span> Central Limit Theorem</h2>
<p><strong>Central Limit Theorem</strong> or <strong>CLT</strong> is the singularly most important theorem in statistics. CLT forms the foundation of <strong>statistical inference</strong>, a subject of perpetual interest in statistics.</p>
<div id="presenting-central-limit-theorem" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Presenting Central Limit Theorem</h3>
<ol style="list-style-type: decimal">
<li>Given a random variable Y of <strong>any shape</strong> with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>,</li>
</ol>
<p><span class="math display">\[Y \sim \forall(\mu,\sigma^2)\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><p>We choose a random sample from Y <span class="math display">\[Y_1, Y_2, Y_3, ..., Y_n ~ \overset{iid}{\sim} ~ \forall(\mu,\sigma^2)\]</span> where each <span class="math inline">\(Y_i\)</span> is a random variable with <span class="math inline">\(E(Y_i) = \mu\)</span> and <span class="math inline">\(Var(Y_i) = \sigma^2\)</span>.</p></li>
<li><p>We can compute the sampling statistic of the sample mean <span class="math display">\[\bar{Y} = \frac{1}{n} \sum_{i=1}^{n} Y_i\]</span> where <span class="math inline">\(\bar{Y}\)</span> becomes another random variable.</p></li>
<li><p>Hence, we would immediately ask the question: What are the properties of <span class="math inline">\(\bar{Y}\)</span>?</p></li>
</ol>
<p>The answer to this question gives birth to the singularly most important theorem in statistics, known as the <strong><em>Central Limit Theorem</em></strong> or <strong>CLT</strong>. See the proof of part of the theorem below.</p>
<p><strong>Answers</strong>: <span class="math display">\[\bar{Y} \sim N \left( \mu, \frac{\sigma^2}{n} \right)\]</span> or equivalently</p>
<ul>
<li><span class="math inline">\(E(\bar{Y}) = \mu\)</span></li>
<li><span class="math inline">\(Var(\bar{Y}) = \sigma^2 / n\)</span></li>
<li><span class="math inline">\(shape(\bar{Y}) = N\)</span></li>
</ul>
<p>The most surprising part of the CLT is the discovery that given a random variable <span class="math inline">\(Y\)</span> of <strong>any</strong> distribution, <span class="math inline">\(\bar{Y}\)</span> is <strong>always</strong> normally distributed as long as two conditions are satisfied:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(Y_1, Y_2, Y_3, ..., Y_n ~ \overset{iid}{\sim} ~ \forall(\mu,\sigma^2)\)</span></li>
<li>sample size n is large enough</li>
</ol>
<p><code>Proof - Prerequisites</code>:</p>
<ul>
<li><span class="math inline">\(E(cX) = c E(X)\)</span></li>
<li><span class="math inline">\(E(X+Y) = E(X) + E(Y)\)</span></li>
<li><span class="math inline">\(E(cX) = c^2E(X)\)</span></li>
<li><span class="math inline">\(Var(X+Y) = Var(X) + Var(Y)\)</span> if <span class="math inline">\(X \perp Y\)</span>, i.e., X is independent of Y</li>
</ul>
<p><code>Proof</code>: <span class="math display">\[E(\bar{Y}) = E( \frac{1}{n} \sum_{i=1}^{n} Y_i ) = \frac{1}{n} E( \sum_{i=1}^{n} Y_i ) 
= \frac{1}{n} \sum_{i=1}^{n} E(Y_i) =  \frac{1}{n} \sum_{i=1}^{n} \mu 
= \frac{1}{n} n\mu = \mu\]</span></p>
<p>and</p>
<p><span class="math display">\[Var(\bar{Y}) = Var( \frac{1}{n} \sum_{i=1}^{n} Y_i ) 
= \frac{1}{n^2} Var( \sum_{i=1}^{n} Y_i ) 
= \frac{1}{n^2} \sum_{i=1}^{n} Var(Y_i) =  \frac{1}{n^2} \sum_{i=1}^{n} \sigma^2 
= \frac{1}{n^2} n\sigma^2 = \frac{\sigma^2}{n}\]</span></p>
<p>Note that the proof of <span class="math inline">\(E(\bar{Y}) = \mu\)</span> and <span class="math inline">\(Var(\bar{Y}) = \sigma^2 / n\)</span> are very straitforward. However, showing that the <span class="math inline">\(shape(\bar{Y}) = N\)</span> is much more difficult and is beyond the scope of this book. The third point is in fact the most important contribution of the Central Limit Theorem.</p>
</div>
<div id="understanding-central-limit-theorem" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Understanding Central Limit Theorem</h3>
<div id="htmlwidget-3ba03b5d9847b1d84d38" style="width:672px;height:250px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-3ba03b5d9847b1d84d38">{"x":{"diagram":"\ngraph LR\n\nA(Random Variable) -->|Sampling|B(Sample)\nB -->|Inference|A\nB --> C(Case1)\nB --> D(Case2)\nB --> E(Case3)\nB --> F(Case4)\n\n"},"evals":[],"jsHooks":[]}</script>
<div id="sampling-process" class="section level4">
<h4><span class="header-section-number">4.2.2.1</span> Sampling Process</h4>
<p>Given a random variable, the sampling process is the process of getting a sample of cases. Get a case involves two steps: (1) choose and (2) measure.</p>
<div class="figure">
<img src="images/inference_measure.png" />

</div>
<p>To sum up,</p>
<ol style="list-style-type: decimal">
<li>Y is a RV <code>&lt;=&gt;</code> <span class="math inline">\(\bar{Y} \sim N(\mu, \sigma^2)\)</span></li>
<li>choose a random sample from Y <code>&lt;=&gt;</code> <span class="math inline">\(Y_1, Y_2, Y_3, ..., Y_n ~ \overset{iid}{\sim} ~ \forall(\mu,\sigma^2)\)</span></li>
<li>choose a sample from Y <code>&lt;=&gt;</code> <span class="math inline">\(y_1, y_2, y_3, ..., y_n\)</span></li>
</ol>
</div>
<div id="inference" class="section level4">
<h4><span class="header-section-number">4.2.2.2</span> Inference</h4>
<p>Given a sample of cases, inference is the process of estimating properties of the original random variable. The first and foremost question to ask is</p>
<blockquote>
<p>How to estimate the population mean <span class="math inline">\(\mu\)</span>?</p>
</blockquote>
<p>An intuitive reaction is to consider using sample mean <span class="math inline">\(\bar{y}\)</span> to estimate population mean <span class="math inline">\(\mu\)</span>. Since each time we collect a sample, the sample mean will change. It is thus natural to consider the sampling distribution of sample mean and the answer is readily given by the CLT.</p>
<p><span class="math display">\[\bar{Y} \sim N \left( \mu, \frac{\sigma^2}{n} \right)\]</span></p>
<div class="figure">
<img src="images/inference_estimate.png" />

</div>
</div>
<div id="further-notes" class="section level4">
<h4><span class="header-section-number">4.2.2.3</span> Further Notes</h4>
<p>Another way to present CLT is</p>
<p><span class="math display">\[\sum Y_i = n\bar{Y} \sim N( n\mu, n \sigma^2 )\]</span> which suggests that <strong>any random disturbances added together</strong> would give rise to <strong>a normal distribution</strong>.</p>
<p>Given the CLT</p>
<p><span class="math display">\[\bar{Y} \sim N \left( \mu, \frac{\sigma^2}{n} \right)\]</span></p>
<p>we know that <span class="math inline">\(\bar{Y}\)</span> is called the <strong>sample mean</strong>; <span class="math inline">\(N\)</span> is a probability distribution; <span class="math inline">\(\mu\)</span> is a mean; <span class="math inline">\(\sigma^2/n\)</span> is a variance; and <span class="math inline">\(\sqrt{\sigma^2/n}\)</span> is the standard deviation.</p>
<p>Since the sampling process and inference are so important, we would invent some new terms.</p>
<ul>
<li><span class="math inline">\(\bar{Y}\)</span> is the <em>sample mean</em> that is generally known as a <strong>sample statistic</strong></li>
<li><span class="math inline">\(N\)</span> is called a <strong>sampling distribution</strong>, or in this context, the sampling distribution of the sample mean</li>
<li><span class="math inline">\(\sqrt{\sigma^2/n}\)</span> is called the <strong>standard error</strong> that is the standard deviation of the sampling distribution of the sample mean</li>
<li><code>Definition</code>: <strong><em>sampling distribution</em></strong> is the <em>probability distribution</em> of a sample statistic</li>
<li><code>Definition</code>: <strong><em>standard error</em></strong> that is the <em>standard deviation</em> of a sample statistic</li>
</ul>
</div>
</div>
</div>
<div id="statistical-inference-1" class="section level2">
<h2><span class="header-section-number">4.3</span> Statistical Inference</h2>
<p>Statistical inference is a formal mathematical technique used to <strong>infer whether a hypothesis is true based on existing evidence</strong>, i.e., data that we have collected.</p>
<div id="the-diamond-expert" class="section level3">
<h3><span class="header-section-number">4.3.1</span> The Diamond Expert</h3>
<p>Imagine that you are an expert on diamonds. You have studied and seen so many diamonds for so long that you know everything about them. One day a close friend of yours called you and asked you to help him to inspect whether a newly acquired diamond is authentic or not. Let’s pretend that evaluating a diamond would take quite some time and money to do so. Now that your friend comes to your place and gleefully reveals a surprisingly large diamond of 30 cm in diameter. Without doing any technical assessment formally, simply by your gut feeling</p>
<blockquote>
<p>Do you think the diamond is authentic or not?</p>
</blockquote>
<p><strong>Answer</strong>: If you ask me, I would say the diamond is too big to be real. It’s got to be a fake.</p>
<p>Let’s rationalize this gut feel using some mathematics. Since you are the diamond expert, you know that real diamonds would average 0.5 cm in diameter with a standard deviation of 0.3 cm. As a result, if the diamond is real (this is your hypothesis), 30 cm in diameter would translate into a large z-score of about 98. In other words, the probability of seeing a real diamond as large as 30 cm would be infinitesimally small. At this point you need to make a choice between two possible scenarios:</p>
<ol style="list-style-type: decimal">
<li>Your hypothesis holds (i.e., the diamond is real) and you are lucky enough to have seen an extremely rare event.</li>
<li>You cannot be so lucky to see such a rare event. The hypothesis has got to be wrong (i.e., the diamond is fake).</li>
</ol>
<p>In our case, since the probability of seeing a gigantic diamond of 30 cm is so small, our gut feeling readily accepts scenario two. In an instant, the convoluted but precise mathematical rationale presented above would be encapsulated by our good intuition that <strong>this diamond is too big to be real!</strong></p>
<p>The gut feeling we have replied on is the essence of statistial inference, i.e., making a decision based on a probability computed under a proposed hypothesis. The process can be formalized as follows:</p>
<ol style="list-style-type: decimal">
<li>State a hypothesis</li>
<li>Compute a probability under the hypotheis</li>
<li>Make a decision based on pre-determined rule</li>
</ol>
</div>
<div id="hypothesis-testing" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Hypothesis Testing</h3>
<p>With a specific normal distribution, there is always a small probability, no matter how small, that an extreme case is indeed coming from the normal distribution. As a result, we need to agree on certain pre-determined cutoffs beyond which extreme cases are flagged as highly unlikely, i.e., <strong>too big to be true</strong>. The cutoffs we use would correspond to the tail regions summing up to 5% probability, i.e., <span class="math inline">\(\boldsymbol{\alpha=0.05}\)</span>, where <span class="math inline">\(\alpha\)</span> is formally referred to as the <strong>Type I Error Rate</strong> or <strong>False Positive Rate</strong>.</p>
<div id="hypothesis-testing-with-n01" class="section level4">
<h4><span class="header-section-number">4.3.2.1</span> Hypothesis Testing with <span class="math inline">\(N(0,1)\)</span></h4>
<p><img src="_main_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Under the standard normal distribution, the cutoff for the lower tail <span class="math inline">\(z_L=\)</span> -1.959964, i.e., <code>qnorm(0.025)</code> and the cutoff for the upper tail <span class="math inline">\(z_U=\)</span> 1.959964, i.e., <code>qnorm(0.975)</code>.</p>
</div>
<div id="hypothesis-testing-with-known-variance" class="section level4">
<h4><span class="header-section-number">4.3.2.2</span> Hypothesis Testing with Known Variance</h4>
<p>Let’s now consider the CLT, where both <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> are population parameters and are hence constants.</p>
<p><span class="math display">\[\bar{Y} \sim N \left( \mu, \frac{\sigma^2}{n} \right)\]</span></p>
<p>In hypothesis testing, <span class="math inline">\(\mu\)</span> is a hypothesized value proposed by and hence known to the researcher. For the present, we assume that <span class="math inline">\(\sigma\)</span> is also known to us. To find the cutoffs for <span class="math inline">\(\bar{Y}\)</span>, i.e., <span class="math inline">\(\bar{Y}_L\)</span> and <span class="math inline">\(\bar{Y}_U\)</span>, we would first convert them into z-scores, i.e., <span class="math inline">\(z_L\)</span> and <span class="math inline">\(z_U\)</span></p>
<p><span class="math display">\[z_L = \frac{\bar{Y}_L - \mu}{\sqrt{\frac{\sigma^2}{n}}}\]</span> and <span class="math display">\[z_U = \frac{\bar{Y}_U - \mu}{\sqrt{\frac{\sigma^2}{n}}}\]</span></p>
<p>Solving for <span class="math inline">\(\bar{Y}_L\)</span> and <span class="math inline">\(\bar{Y}_U\)</span> and substituting the values of <span class="math inline">\(z_L\)</span> and <span class="math inline">\(z_U\)</span>, we have <span class="math display">\[\bar{Y}_L = \mu + z_L \sqrt{\frac{\sigma^2}{n}} = \mu - 1.96 \sqrt{\frac{\sigma^2}{n}}\]</span> and <span class="math display">\[\bar{Y}_U = \mu + z_U \sqrt{\frac{\sigma^2}{n}} = \mu + 1.96 \sqrt{\frac{\sigma^2}{n}}\]</span></p>
<p>As a result, given a specific <span class="math inline">\(\bar{y}\)</span> computed from a settled sample, if <span class="math inline">\(\bar{y} &lt; \bar{Y}_L\)</span> or <span class="math inline">\(\bar{y} &gt; \bar{Y}_U\)</span>, we would reject that hypothesis that <span class="math inline">\(\bar{y}\)</span> is coming from a distribution with mean <span class="math inline">\(\mu\)</span>. We would therefore refer to <span class="math inline">\(\bar{y} &lt; \bar{Y}_L\)</span> and <span class="math inline">\(\bar{y} &gt; \bar{Y}_U\)</span> as the <strong>rejection regions</strong>. On the contrary, we will call <span class="math inline">\(\bar{Y}_L \le \bar{y} \le \bar{Y}_U\)</span> or <span class="math inline">\((\bar{Y}_L, \bar{Y}_U)\)</span> the <strong>acceptance regions</strong>.</p>
</div>
<div id="confidence-interval-with-known-variance" class="section level4">
<h4><span class="header-section-number">4.3.2.3</span> Confidence Interval with Known Variance</h4>
<p>Given the two previous cutoffs, we can have</p>
<p><span class="math display">\[P(\bar{Y}_L \le \bar{Y} \le \bar{Y}_U) = 0.95\]</span></p>
<p>To note, this is a valid probability representation, which must have the form <span class="math inline">\(P(a \le X \le b) = p\)</span>, where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are constants, <span class="math inline">\(X\)</span> is a random variable, and <span class="math inline">\(0 \le p \le 1\)</span>.</p>
<p>Now, let’s substitute the values of <span class="math inline">\(\bar{Y}_L\)</span> and <span class="math inline">\(\bar{Y}_L\)</span>.</p>
<p><span class="math display">\[P \left(\mu - 1.96 \sqrt{\frac{\sigma^2}{n}} \le \bar{Y} \le \mu + 1.96 \sqrt{\frac{\sigma^2}{n}} \right) = 0.95\]</span></p>
<p>It must be emphasized again that the above equation is a valid probability representation since <span class="math inline">\(\bar{Y}\)</span> is a random variable and <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are constants (<span class="math inline">\(\mu\)</span> is a hypothesized value and <span class="math inline">\(\sigma\)</span> is known to us).</p>
<p>Now, let’s focus on the left part of the inequality within the probability equation.</p>
<p><span class="math display">\[\mu - 1.96 \sqrt{\frac{\sigma^2}{n}} \le \bar{Y}\]</span> We can easily rearrange it and have</p>
<p><span class="math display">\[\mu \le \bar{Y} + 1.96 \sqrt{\frac{\sigma^2}{n}}\]</span></p>
<p>Similarly, by focusing on the right part of the inequality and rearrange it, we will have</p>
<p><span class="math display">\[\bar{Y} - 1.96 \sqrt{\frac{\sigma^2}{n}} \le \mu \]</span> Putting together, we will have</p>
<p><span class="math display">\[P \left[\bar{Y} - 1.96 \sqrt{\frac{\sigma^2}{n}} \le \mu \le \bar{Y} + 1.96 \sqrt{\frac{\sigma^2}{n}} \right] = 0.95\]</span> or <span class="math display">\[ P[LB \le \mu \le UB] = 0.95 \]</span> where <span class="math inline">\(LB = \bar{Y} - 1.96 \sqrt{\sigma^2/n}\)</span> and <span class="math inline">\(UB = \bar{Y} + 1.96 \sqrt{\sigma^2/n}\)</span>. To note, LB stands for lower bound and UB for upper bound.</p>
<p>Notice that we are using <code>[]</code> instead of <code>()</code> because this equation above is not a valid probability representation.</p>
<p>The resulting <span class="math inline">\([LB, UP]\)</span> is called the <strong>confidence interval</strong> or <strong>IC</strong> at 95% level, i.e. <span class="math inline">\(1-\alpha\)</span>.</p>
</div>
<div id="margin-of-error" class="section level4">
<h4><span class="header-section-number">4.3.2.4</span> Margin of Error</h4>
<p>Previously, we have introduced <span class="math inline">\(\sqrt{\sigma^2/n}\)</span> as the <strong>standard error</strong> or <span class="math inline">\(\mathbf{se}\)</span>. Now we would introduce a new concept called the <strong>margin of error</strong> or <span class="math inline">\(\mathbf{me}\)</span>.</p>
<p><span class="math display">\[\text{me} = z_{(1-\frac{\alpha}{2})} \sqrt{\frac{\sigma^2}{n}} \]</span> where <span class="math inline">\(z_{(1-\alpha/2)}\)</span> is computed by <code>qnorm(1-alpha/2)</code> and <code>alpha</code> is the type I error rate <span class="math inline">\(\alpha\)</span>. By default, <span class="math inline">\(\alpha = 0.05\)</span> and hence <span class="math inline">\(z_{(1-\alpha/2)} = 1.96\)</span>.</p>
<p>Hence it should be clear that <span class="math inline">\(\mu \pm \text{me}\)</span> gives the <strong>acceptance regions</strong> and <span class="math inline">\(\bar{y} \pm \text{me}\)</span> gives the <strong>confidence interval</strong>. In other words, with <span class="math inline">\(\mu\)</span> in the center and reaching out to the left and right by <span class="math inline">\(\text{me}\)</span>, we will have the acception regions. With <span class="math inline">\(\bar{y}\)</span> in the center and reaching out to the left and right by <span class="math inline">\(\text{me}\)</span>, we will have the confidence interval.</p>
</div>
<div id="further-notes-1" class="section level4">
<h4><span class="header-section-number">4.3.2.5</span> Further Notes</h4>
<ol style="list-style-type: decimal">
<li>Interpretation of Confidence Interval</li>
</ol>
<p>Given the confidence interval</p>
<p><span class="math display">\[P \left[\bar{Y} - 1.96 \sqrt{\frac{\sigma^2}{n}} \le \mu \le \bar{Y} + 1.96 \sqrt{\frac{\sigma^2}{n}} \right] = 0.95\]</span></p>
<p>one should <strong>NOT</strong> interpret it as follows: The probability that the true population mean <span class="math inline">\(\mu\)</span> would fall between LB and UB is 95%.</p>
<p>The correct interpretation is: The numerous sets of confidence interval as generated by the current estimator <span class="math inline">\(\bar{Y}\)</span> will have a 95% chance of capturing the true population mean <span class="math inline">\(\mu\)</span>.</p>
<p>To someone who is new to statistics, chances are that the more you would think about how the two claims are different, the more you will get confused. The differences are more cosmetic than practical. In fact, if you adopt a Bayesian view of statistics, the first claim would turn out to be true. However, frequentists would regard the first claim as categorically wrong, because it violates the valid form of a probability representation, i.e., <span class="math inline">\(P(a \le X \le b) = p\)</span>.</p>
<ol start="2" style="list-style-type: decimal">
<li>No Acceptance of a Null Hypothesis</li>
</ol>
</div>
</div>
<div id="hypothesis-testing-with-unknown-variance" class="section level3">
<h3><span class="header-section-number">4.3.3</span> Hypothesis Testing with Unknown Variance</h3>
<div id="pivotal-quantity" class="section level4">
<h4><span class="header-section-number">4.3.3.1</span> Pivotal Quantity</h4>
<p>Previous discussion on hypothesis testing and confidence interval revolves around a critically important equation, where <span class="math inline">\(z\)</span> is a random variable and is known as the <strong>z statistic</strong>.</p>
<p><span class="math display">\[z = \frac{\bar{Y} - \mu}{\sqrt{\frac{\sigma^2}{n}}}\]</span></p>
<p>In this equation, <span class="math inline">\(\bar{Y}\)</span> is called the <strong>estimator</strong> and <span class="math inline">\(\mu\)</span> is called the <strong>estimand</strong>, <span class="math inline">\(z\)</span> is of known distribution, and all the other parameters <span class="math inline">\(\sigma\)</span> and <span class="math inline">\(n\)</span> are known. In situations like this one, the equation is known as a <strong>pivotal quanity</strong>.</p>
<p>Finding the pivotal quanity is critically important, because both conducting hypothesis testing and finding confidence interval depend on it.</p>
</div>
<div id="from-z-to-t-statistic" class="section level4">
<h4><span class="header-section-number">4.3.3.2</span> From Z to T Statistic</h4>
<p>Let’s define some new terms.</p>
<ul>
<li>residual <span class="math display">\[R_i = Y_i - \bar{Y}\]</span></li>
<li>residual variance <span class="math display">\[s^2 = \frac{\sum R_i^2}{df} = \frac{\sum (Y_i-\hat{Y})^2}{df} \overset{\hat{Y}=\bar{Y}}{\rightarrow} \frac{\sum (Y_i-\bar{Y})^2}{n-1}\]</span></li>
<li>chi-square <span class="math display">\[\frac{\sum R_i^2}{\sigma^2} \sim \chi_{df}^2\]</span></li>
<li>t-statistic <span class="math display">\[t = \frac{z}{\sqrt{\frac{\chi^2}{df}}}\]</span></li>
</ul>
<p>Now, let’s focus on the t-statistic and substitute the corresponding terms into it.</p>
<p><span class="math display">\[t = \frac{z}{\sqrt{\frac{\chi^2}{df}}} 
= \frac{\frac{\bar{Y} - \mu}{\sqrt{\frac{\sigma^2}{n}}} }{\sqrt{\frac{\sum R_i^2}{\sigma^2} \cdot \frac{1}{df}}}
= \frac{\frac{\bar{Y} - \mu}{\sqrt{\frac{\sigma^2}{n}}} }{\sqrt{\frac{s^2 \cdot df}{\sigma^2} \cdot \frac{1}{df}}}
= \frac{\bar{Y} - \mu}{\sqrt{\frac{s^2}{\sigma^2} \cdot \frac{\sigma^2}{n}}}
= \frac{\bar{Y} - \mu}{\sqrt{\frac{s^2}{n}}}\]</span></p>
<p>The result can be summary as follows. <span class="math display">\[t = \frac{\bar{Y} - \mu}{\sqrt{\frac{s^2}{n}}}\]</span></p>
<p>To note, compared to the z-statistic, the t-statistic is also a pivotal quantity, where <span class="math inline">\(t\)</span> is of a known distribution and <span class="math inline">\(s^2\)</span> is the sample variance that can be easily computed.</p>
</div>
<div id="hypothesis-testing-revisited" class="section level4">
<h4><span class="header-section-number">4.3.3.3</span> Hypothesis Testing Revisited</h4>
<p>To account for the unknown variance <span class="math inline">\(\sigma^2\)</span>, let’s replace z-statistic with t-statistic and redo the previous derivations. We will have</p>
<ul>
<li>acceptance regions for hypothesis testing <span class="math display">\[\mu \pm z_{(1-\frac{\alpha}{2})} \sqrt{\frac{\sigma^2}{n}} 
~~ \rightarrow ~~ 
\mu \pm t_{(1-\frac{\alpha}{2})} \sqrt{\frac{s^2}{n}}\]</span></li>
<li>confidence interval <span class="math display">\[\bar{Y} \pm z_{(1-\frac{\alpha}{2})} \sqrt{\frac{\sigma^2}{n}} 
~~ \rightarrow ~~ 
\bar{Y} \pm t_{(1-\frac{\alpha}{2})} \sqrt{\frac{s^2}{n}}\]</span></li>
</ul>
</div>
</div>
<div id="examples-of-hypothesis-testing" class="section level3">
<h3><span class="header-section-number">4.3.4</span> Examples of Hypothesis Testing</h3>
<div id="one-sample-t-test" class="section level4">
<h4><span class="header-section-number">4.3.4.1</span> One-sample T-Test</h4>
<p>We are conducting a survey asking students to rate the overall quality of a specific course. The question is framed on a <strong>Likert scale</strong> from 1 to 6 with 1 being the most negative response and 6 the most positive response. An example of this would be as follows:</p>
<pre><code>Do you agree with the following statement:

The course is well taught overall. 
1 - strongly disagree
2 - disagree
3 - mildly disagree
4 - mildly agree
5 - agree
6 - strongly agree</code></pre>
<p>Strictly speaking, student rating is an ordinal variable. In practice, however, we would treat it as an interval variable with the assumption that the spacings between any two consecutive ratings are equidistant.</p>
<p>Let’s pretend we have collected data from a sample of 56 students. The average rating is 3.8 with a standard deviation of 1.2. The question is</p>
<blockquote>
<p>Is the average student rating truly different from being neutral?</p>
</blockquote>
<p>Let’s summarize and present some statistics.</p>
<ul>
<li><span class="math inline">\(n = 56\)</span></li>
<li><span class="math inline">\(\bar{y}=3.8\)</span></li>
<li><span class="math inline">\(s=1.2\)</span></li>
<li><span class="math inline">\(t_{(p=0.975,~df=n-1)} = 2.004\)</span>, result of <code>qt(p=0.975, df=55)</code></li>
<li><span class="math inline">\(s/\sqrt{n} = 0.2/\sqrt{56} = 0.160\)</span></li>
</ul>
<ol style="list-style-type: decimal">
<li>propose the hypothesis</li>
</ol>
<p>Under the hypothesis that average student rating is indeed neutral, we have <span class="math inline">\(\mu = 3.5\)</span>.</p>
<ol start="2" style="list-style-type: decimal">
<li><p>compute a probability under the hypothesis <span class="math display">\[t = \frac{\bar{Y} - \mu}{\sqrt{\frac{s^2}{n}}} = \frac{3.8 - 3.5}{0.160} = 1.875\]</span> Using R code <code>p = 2 * ( 1 - pt(1.875, df=56-1) )</code>, we have p = 0.067.</p></li>
<li><p>make a decision</p></li>
</ol>
<p>Given p = 0.067 and our pre-determined cutoff is <span class="math inline">\(\alpha = 0.05\)</span>, we should <strong>NOT</strong> reject our hypothesis, since the observed average 3.8 is not <strong>statistically significantly different</strong> from the neurality of 3.5.</p>
</div>
<div id="paired-t-test" class="section level4">
<h4><span class="header-section-number">4.3.4.2</span> Paired T-Test</h4>
<p>Imagine we are conducting two surveys to measure student interests in the course. One survey is delivered in the beginning of the course and the other by the end of the course. This is a typical <strong>pre-test</strong> and <strong>post-test</strong> scenario.</p>
<p>Use the following code to generate some data and use the data to conduct the needed statistical test.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
rating1 =<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">size=</span><span class="dv">56</span>, <span class="dt">replace=</span>T, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>))
rating2 =<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">size=</span><span class="dv">56</span>, <span class="dt">replace=</span>T, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">3</span>))</code></pre></div>
<p>=======</p>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="the-fundamentals-of-statistics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="statistical-inference-2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
